# Transformer & LLM Mechanism Resources

This document gathers a variety of resources—from GitHub repositories and interactive notebooks to research papers and blog posts—that all contribute to understanding the inner workings and interpretability of transformer models and LLMs.

---

## Overview

- **Analytical Toolkits & Visualizations:**  
  Repositories such as [TransformerLens](https://github.com/TransformerLensOrg/TransformerLens?tab=readme-ov-file), [llava-mechanism](https://github.com/zepingyu0512/llava-mechanism/tree/main), [llava-interp](https://github.com/clemneo/llava-interp), and [pyvene](https://github.com/stanfordnlp/pyvene) provide the software and notebooks needed to visually dissect transformer behaviors, making abstract model internals accessible and interpretable.

- **Curated Resource Lists:**  
  The awesome lists ([Awesome LLM Mechanism Analysis](https://github.com/HaitaoMao/Awesome-LLM-Mechanism-Analysis) and [awesome-llm-understanding-mechanism](https://github.com/zepingyu0512/awesome-llm-understanding-mechanism?tab=readme-ov-file)) compile research papers, tools, and blog posts, thereby serving as comprehensive guides for researchers and enthusiasts delving into LLM interpretability.

- **Interactive Demos & Notebooks:**  
  The [TransformerLens Exploratory Analysis Demo](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb#scrollTo=hYOEX3xpQoVz) offers a hands-on way to engage with transformer data, reinforcing concepts that are also discussed in the academic papers and blog posts.

- **Research Papers & In-Depth Analyses:**  
  A suite of arXiv papers (IDs such as 2404.14082, 2310.01405, 2211.00593, and others) provides the theoretical and experimental backbone, elaborating on mechanisms like in-context learning, induction heads, and the internal dynamics of transformer models. These works help bridge the gap between raw code implementations and high-level model interpretations.

- **Accessible Explanations & Industry News:**  
  Blog posts from Transformer Circuits (e.g., [In-Context Learning and Induction Heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html) and [Toy Model](https://transformer-circuits.pub/2022/toy_model/index.html)) present complex research in a more digestible format, while industry updates such as Anthropic’s [Golden Gate Claude announcement](https://www.anthropic.com/news/golden-gate-claude) demonstrate how these theoretical insights are driving real-world LLM innovations.

- **Visualization & Interactive Exploration:**  
  Websites like [functions.baulab.info](https://functions.baulab.info/) offer interactive visualizations that complement the static analysis found in both code repositories and research papers, fostering a more intuitive grasp of underlying model functions.

---

## Resource Classifications

1. **TransformerLens Repository (GitHub)**  
   _URL:_ [TransformerLens](https://github.com/TransformerLensOrg/TransformerLens?tab=readme-ov-file)  
   A toolkit designed to visualize and analyze the internal mechanisms of transformer models.

2. **LLAVA Mechanism Repository (GitHub)**  
   _URL:_ [llava-mechanism](https://github.com/zepingyu0512/llava-mechanism/tree/main)  
   A repository focused on exploring and demystifying the mechanisms behind the LLAVA system.

3. **LLAVA Visualization Notebook (GitHub)**  
   _URL:_ [LLava_visualize_code.ipynb](https://github.com/zepingyu0512/llava-mechanism/blob/main/Llava_visualize_code.ipynb)  
   A Jupyter Notebook that demonstrates how to visualize model behavior and mechanisms in LLAVA.

4. **LLAVA Interpreter Repository (GitHub)**  
   _URL:_ [llava-interp](https://github.com/clemneo/llava-interp)  
   A set of tools and scripts aimed at interpreting and understanding the decision processes of the LLAVA model.

5. **Pyvene (GitHub)**  
   _URL:_ [pyvene](https://github.com/stanfordnlp/pyvene)  
   A Python library from Stanford NLP that aids in analyzing and visualizing aspects of NLP models, including transformer internals.

6. **Awesome LLM Mechanism Analysis (GitHub)**  
   _URL:_ [Awesome-LLM-Mechanism-Analysis](https://github.com/HaitaoMao/Awesome-LLM-Mechanism-Analysis)  
   A curated list of resources and research focused on the analysis of large language model mechanisms.

7. **TransformerLens Exploratory Analysis Demo (Colab Notebook)**  
   _URL:_ [Exploratory Analysis Demo](https://colab.research.google.com/github/neelnanda-io/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb#scrollTo=hYOEX3xpQoVz)  
   An interactive Colab notebook that demonstrates exploratory analysis techniques using TransformerLens.

8. **ArXiv Paper 2404.14082**  
   _URL:_ [2404.14082](https://arxiv.org/pdf/2404.14082)  
   A research paper presenting new insights into transformer mechanism interpretability.

9. **ArXiv Paper 2310.01405**  
   _URL:_ [2310.01405](https://arxiv.org/pdf/2310.01405)  
   A study exploring key aspects of transformer models, contributing to the understanding of their internal workings.

10. **Anthropic Golden Gate Claude Announcement**  
    _URL:_ [Golden Gate Claude](https://www.anthropic.com/news/golden-gate-claude)  
    A news article from Anthropic announcing their Golden Gate Claude model and its advancements in LLM capabilities.

11. **In-Context Learning and Induction Heads (Transformer Circuits Blog)**  
    _URL:_ [In-Context Learning and Induction Heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)  
    A blog post that explains how transformers learn from context and the critical role of induction heads in this process.

12. **Toy Model Analysis (Transformer Circuits Blog)**  
    _URL:_ [Toy Model](https://transformer-circuits.pub/2022/toy_model/index.html)  
    A blog post using a simplified toy model to demonstrate and explain core transformer mechanisms.

13. **ArXiv Paper 2211.00593**  
    _URL:_ [2211.00593](https://arxiv.org/pdf/2211.00593)  
    A research paper offering in-depth analysis into transformer interpretability and the underlying mechanisms of these models.

14. **ArXiv Paper 2402.14811**  
    _URL:_ [2402.14811](https://arxiv.org/pdf/2402.14811)  
    A scholarly article examining novel findings in transformer mechanism analysis and model interpretability.

15. **ArXiv Paper 2406.11944**  
    _URL:_ [2406.11944](https://arxiv.org/pdf/2406.11944)  
    A research paper focused on advanced topics in transformer internals and the dynamics of LLM mechanisms.

16. **Baulab Functions**  
    _URL:_ [functions.baulab.info](https://functions.baulab.info/)  
    An interactive website offering visualization tools for exploring functions relevant to understanding LLM mechanisms.

17. **ArXiv Paper 2410.07149**  
    _URL:_ [2410.07149](https://arxiv.org/pdf/2410.07149)  
    A recent research paper that delves into new developments in transformer interpretability.

18. **ArXiv Paper 2411.10950**  
    _URL:_ [2411.10950](https://arxiv.org/pdf/2411.10950)  
    A study presenting innovative insights into the internal workings and mechanisms of transformer models.

19. **Awesome LLM Understanding Mechanism (GitHub)**  
    _URL:_ [awesome-llm-understanding-mechanism](https://github.com/zepingyu0512/awesome-llm-understanding-mechanism?tab=readme-ov-file)  
    A curated repository compiling diverse resources aimed at demystifying the mechanisms behind large language models.

20. **ArXiv Paper 2401.01967**  
    _URL:_ [2401.01967](https://arxiv.org/pdf/2401.01967)  
    A research paper investigating dynamics and interpretability aspects of transformer model behavior.

21. **ArXiv Paper 2411.17491**  
    _URL:_ [2411.17491](https://arxiv.org/pdf/2411.17491)  
    A scholarly article that explores new theories and experimental findings on transformer internals.

22. **ArXiv Paper 2410.07149v1**  
    _URL:_ [2410.07149v1](https://arxiv.org/pdf/2410.07149v1)  
    The initial version of a research paper offering early insights into transformer interpretability.

23. **ArXiv Paper 2402.16837v1**  
    _URL:_ [2402.16837v1](https://arxiv.org/pdf/2402.16837v1)  
    An early research paper that provides foundational perspectives on the mechanisms within transformer architectures.

24. **ArXiv Paper 2407.10827v1**  
    _URL:_ [2407.10827v1](https://arxiv.org/pdf/2407.10827v1)  
    An initial version of a study exploring novel aspects of transformer model mechanisms.
